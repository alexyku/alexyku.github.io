<!DOCTYPE html>
<meta charset="utf-8">
<head>
  <link rel="icon" href="mepics/logo.png" tleype="image/gif" >
  <link rel="stylesheet" href="style.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
  <title>Alexander Ku</title>
</head>
<body>
  <div class="table">
    <div class="row">
      <div class="col-8">
        <h1 style="margin-top: 0;">Alexander Ku</h1>
        I'm a PhD student in Psychology and Neuroscience at Princeton, working with <a href="https://cocosci.princeton.edu/tom/index.php">Tom Griffiths</a> and <a href="https://jdc.princeton.edu/">Jon Cohen</a>. 
        I'm also a Research Scientist at Google DeepMind. I did my undergrad and master's in Computer Science at UC Berkeley
        <br><br>
        My research focuses on the computational principles that enable both short-term flexibility and long-term efficiency in people and machines.
        At the core of this relationship is how internal representations of the external world are learned and transformed.
        I believe a deeper understanding of how experience and environmental demands shape these representations is essential for building continually adaptive artificial systems.
        <!-- I study the computational principles that allow for both short-term flexibility and long-term efficiency in minds and machines.
        At the core of this relationship is how internal representations of the external world are learned and transformed.
        A deeper understanding of how these representations are shaped by experience and environmental demands is essential for developing continually adaptive artificial systems. -->
        <br><br>
        Keywords: Continual Learning, Meta-Learning, Cognitive Control, Automaticity
        <br><br>
        <a href="mailto:alexku@princeton.edu">Email</a> /
        <a href="https://scholar.google.com/citations?user=Lh_ZqdcAAAAJ&hl=en">Google Scholar</a> /
        <a href="https://github.com/alexyku">GitHub</a> /
        <a href="https://twitter.com/alex_y_ku">Twitter</a> /
        <a href="alexku_cv.pdf">CV</a>
      </div>
      <div class="col-4">
        <img src="mepics/AlexKu_041025_0010.jpg">
        <!-- <img src="mepics/AlexKu_111224_0011.jpg"> -->
      </div>
    </div>
    <div class="row">
      <div class="col-12">
        <h2>Selected Papers</h2>
        Recent or representative papers:
        <br><br>
        <a href="https://arxiv.org/abs/2503.13401">Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis</a>
        <br>
        Alexander Ku, Declan Campbell, Xuechunzi Bai, Jiayi Geng, Ryan Liu, Raja Marjieh, R. Thomas McCoy, Andrew Nam, Ilia Sucholutsky, Veniamin Veselovsky, Liyi Zhang, Jian-Qiao Zhu, Thomas L. Griffiths
        <br><br>
        <a href="https://arxiv.org/abs/2505.09855">Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers</a>
        <br>
        Alexander Y. Ku, Thomas L. Griffiths, Stephanie C.Y. Chan
        <br><br>
        <a href="https://arxiv.org/abs/2505.00661">On the Generalization of Language Models from In-Context Learning and Finetuning: A Controlled Study</a>
        <br>
        Andrew K. Lampinen, Arslan Chaudhry, Stephanie C.Y. Chan, Cody Wild, Diane Wan, Alex Ku, JÃ¶rg Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland
        <br><br>
      </div>
    </div>
  </div>
</body>
